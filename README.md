The project focuses on addressing AI-driven threats, particularly the detection of deepfake images, videos, and audio circulating as real news. Our goal is to develop techniques for reliably identifying manipulated media and ensuring the integrity of online information.
The primary goal of this project is to accurately identify deepfake images circulating online, which could be used to promote various agendas. While not everyone fully understands how deepfakes work, this project aims to make it easier for people to distinguish between real and manipulated content. With the help of this tool, users will be able to easily tell if an image or video comes from a legitimate source or if it’s AI-generated. Although the use of generative AI (GenAI) can have positive outcomes, if individuals with malicious intent exploit it, it can lead to the spread of false information. The central theme of this project is to prevent the spread of misinformation caused by deepfake news.
